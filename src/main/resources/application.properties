
quarkus.langchain4j.ollama.model1.base-url=http://localhost:11434
quarkus.langchain4j.ollama.model1.chat-model.model-name=granite3-moe:3b


#quarkus.langchain4j.openai.model1.base-url=
#quarkus.langchain4j.openai.model1.api-key=
#quarkus.langchain4j.openai.model1.chat-model.model-name=granite-3-8b-instruct

#quarkus.langchain4j.openai.model1.chat-model.temperature=0.5
#quarkus.langchain4j.openai.model1.timeout=30s


# quarkus.langchain4j.log-requests=true
# quarkus.langchain4j.log-responses=true

# quarkus.langchain4j.embedding-model.provider=openai
quarkus.langchain4j.model2.embedding-model.provider=dev.langchain4j.model.embedding.onnx.bgesmallenv15.BgeSmallEnV15EmbeddingModel
# quarkus.langchain4j.openai.model2.embedding-model.model-name=granite-embedding-278m-multilingual
# quarkus.langchain4j.openai.model2.base-url=
# quarkus.langchain4j.openai.model2.api-key=
# quarkus.langchain4j.openai.model2.embedding-model.log-requests=true
# quarkus.langchain4j.openai.model2.embedding-model.log-responses=true

#  Use 768 for granite-embedding
# quarkus.langchain4j.milvus.dimension=768
# Use 384 for in-memory BgeSmall.. and others. See https://docs.quarkiverse.io/quarkus-langchain4j/dev/in-process-embedding.html
quarkus.langchain4j.milvus.dimension=384
quarkus.langchain4j.milvus.host=127.0.0.1
quarkus.langchain4j.milvus.port=19530

